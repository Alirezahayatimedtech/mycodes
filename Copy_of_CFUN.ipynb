{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alirezahayatimedtech/mycodes/blob/main/Copy_of_CFUN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/uw-biomedical-ml/RETFound_MAE.git\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-11T17:48:59.60233Z",
          "iopub.execute_input": "2024-08-11T17:48:59.603259Z",
          "iopub.status.idle": "2024-08-11T17:49:00.828759Z",
          "shell.execute_reply.started": "2024-08-11T17:48:59.603218Z",
          "shell.execute_reply": "2024-08-11T17:49:00.826991Z"
        },
        "trusted": true,
        "id": "7E-ln9r2VqUR",
        "outputId": "6b7ce943-f025-4504-8fd3-1f5b777b4329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'RETFound_MAE' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dFJKCuCZ68V",
        "outputId": "cfa6884f-fa25-45a1-a14b-80fa4af92831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch==2.3.1+cu121\n",
        "torchvision==0.18.1+cu121\n",
        "torchaudio==2.3.1+cu121\n",
        "opencv-python\n",
        "pandas\n",
        "Pillow\n",
        "\n",
        "protobuf\n",
        "pycm\n",
        "pydicom\n",
        "scikit-image\n",
        "scikit-learn\n",
        "scipy\n",
        "tensorboard\n",
        "tensorboard-data-server\n",
        "tensorboard-plugin-wit\n",
        "timm\n",
        "tqdm"
      ],
      "metadata": {
        "id": "7tAWdKQHHt2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/RETFound_MAE\n"
      ],
      "metadata": {
        "id": "kLGAziq3VqUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3772c0b1-794d-4b50-edb1-b9392977a61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RETFound_MAE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install CUDA toolkit and cuDNN\n",
        "#!pip install -c conda-forge cudatoolkit=11.2.2 cudnn=8.1.0\n",
        "\n",
        "# Install TensorFlow\n",
        "#!python -m pip install tensorflow==2.8.3\n",
        "\n",
        "# Set the library path\n",
        "#!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
        "\n",
        "# List the number of visible GPUs on the host\n",
        "!python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6O348ZV4NKXT",
        "outputId": "dbddf554-2838-416e-cd60-f8bf4f7cada2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'conda-forge'\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting tensorflow==2.8.3\n",
            "  Downloading tensorflow-2.8.3-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (3.11.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.3)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (3.3.0)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.8.3)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (1.16.0)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.3)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow==2.8.3)\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.3)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.3) (1.64.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.3) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.3) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.3)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.3) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.3) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.3)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.3)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.3) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.3) (3.2.2)\n",
            "Downloading tensorflow-2.8.3-cp310-cp310-manylinux2010_x86_64.whl (498.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.5/498.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-estimator, tensorboard-plugin-wit, keras, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.25.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.23.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.63.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.8.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.3 tensorflow-estimator-2.8.0\n",
            "2024-08-19 09:42:20.970298: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2024-08-19 09:42:20.970337: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2024-08-19 09:42:24.669875: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2024-08-19 09:42:24.669970: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2024-08-19 09:42:24.670019: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7d0f22451fbd): /proc/driver/nvidia/version does not exist\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Colab/CFUN/RETFound_oct_weights.h5 /content/\n"
      ],
      "metadata": {
        "id": "Wo42m2ofZW-B",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/RETFound_MAE\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gnC27MbXM2lo",
        "outputId": "4cffa7a4-bf27-401d-ee4b-702a38177a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RETFound_MAE\n",
            "Requirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: cachetools==5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (5.3.1)\n",
            "Requirement already satisfied: certifi==2023.5.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer==3.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: contourpy==1.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.0.7)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: flatbuffers==23.5.26 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (23.5.26)\n",
            "Requirement already satisfied: fonttools==4.39.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (4.39.4)\n",
            "Requirement already satisfied: gast==0.5.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.5.4)\n",
            "Requirement already satisfied: google-auth==2.19.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.19.0)\n",
            "Requirement already satisfied: google-auth-oauthlib==0.4.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.4.6)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: grpcio==1.54.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.54.2)\n",
            "Requirement already satisfied: h5py==3.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.8.0)\n",
            "Requirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (3.4)\n",
            "Requirement already satisfied: importlib-metadata==6.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (6.6.0)\n",
            "Requirement already satisfied: importlib-resources==5.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (5.12.0)\n",
            "Requirement already satisfied: keras==2.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (2.8.0)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (1.1.2)\n",
            "Requirement already satisfied: kiwisolver==1.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.4.4)\n",
            "Requirement already satisfied: libclang==16.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (16.0.0)\n",
            "Requirement already satisfied: Markdown==3.4.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (3.4.3)\n",
            "Requirement already satisfied: MarkupSafe==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (2.1.2)\n",
            "Requirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (3.7.1)\n",
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (1.24.3)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (3.2.2)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (3.3.0)\n",
            "Requirement already satisfied: packaging==23.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (23.1)\n",
            "Requirement already satisfied: Pillow==9.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (9.5.0)\n",
            "Requirement already satisfied: protobuf==3.19.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (3.19.6)\n",
            "Requirement already satisfied: pyasn1==0.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (0.3.0)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (2.8.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (1.3.1)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (4.9)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard==2.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (2.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server==0.6.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (1.8.1)\n",
            "Requirement already satisfied: tensorflow==2.8.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 43)) (2.8.3)\n",
            "Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 44)) (0.16.1)\n",
            "Requirement already satisfied: tensorflow-estimator==2.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 45)) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (0.32.0)\n",
            "Requirement already satisfied: termcolor==2.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 47)) (2.3.0)\n",
            "Requirement already satisfied: tfimm==0.2.14 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 48)) (0.2.14)\n",
            "Requirement already satisfied: typeguard==4.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 49)) (4.0.0)\n",
            "Requirement already satisfied: typing_extensions==4.6.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (4.6.2)\n",
            "Requirement already satisfied: urllib3==1.26.16 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 51)) (1.26.16)\n",
            "Requirement already satisfied: Werkzeug==2.3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 52)) (2.3.4)\n",
            "Requirement already satisfied: wrapt==1.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 53)) (1.15.0)\n",
            "Requirement already satisfied: zipp==3.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 54)) (3.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse==1.6.3->-r requirements.txt (line 2)) (0.44.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 40)) (71.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tfimm\n",
        "print(tfimm.list_models())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxYC5EG0dqh2",
        "outputId": "0f644510-cc44-4132-fdd2-88009e17aee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cait_m36_384', 'cait_m48_448', 'cait_s24_224', 'cait_s24_384', 'cait_s36_384', 'cait_xs24_384', 'cait_xxs24_224', 'cait_xxs24_384', 'cait_xxs36_224', 'cait_xxs36_384', 'convmixer_768_32', 'convmixer_1024_20_ks9_p14', 'convmixer_1536_20', 'convnext_base', 'convnext_base_384_in22ft1k', 'convnext_base_in22ft1k', 'convnext_base_in22k', 'convnext_large', 'convnext_large_384_in22ft1k', 'convnext_large_in22ft1k', 'convnext_large_in22k', 'convnext_small', 'convnext_small_384_in22ft1k', 'convnext_small_in22ft1k', 'convnext_small_in22k', 'convnext_tiny', 'convnext_tiny_384_in22ft1k', 'convnext_tiny_in22ft1k', 'convnext_tiny_in22k', 'convnext_xlarge_384_in22ft1k', 'convnext_xlarge_in22ft1k', 'convnext_xlarge_in22k', 'deit_base_distilled_patch16_224', 'deit_base_distilled_patch16_384', 'deit_base_patch16_224', 'deit_base_patch16_384', 'deit_small_distilled_patch16_224', 'deit_small_patch16_224', 'deit_tiny_distilled_patch16_224', 'deit_tiny_patch16_224', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet269d', 'ecaresnetlight', 'efficientnet_b0', 'efficientnet_b0_ap', 'efficientnet_b0_ns', 'efficientnet_b1', 'efficientnet_b1_ap', 'efficientnet_b1_ns', 'efficientnet_b2', 'efficientnet_b2_ap', 'efficientnet_b2_ns', 'efficientnet_b3', 'efficientnet_b3_ap', 'efficientnet_b3_ns', 'efficientnet_b4', 'efficientnet_b4_ap', 'efficientnet_b4_ns', 'efficientnet_b5', 'efficientnet_b5_ap', 'efficientnet_b5_ns', 'efficientnet_b6', 'efficientnet_b6_ap', 'efficientnet_b6_ns', 'efficientnet_b7', 'efficientnet_b7_ap', 'efficientnet_b7_ns', 'efficientnet_b8', 'efficientnet_b8_ap', 'efficientnet_el', 'efficientnet_em', 'efficientnet_es', 'efficientnet_l2_ns', 'efficientnet_l2_ns_475', 'efficientnet_lite0', 'efficientnet_lite1', 'efficientnet_lite2', 'efficientnet_lite3', 'efficientnet_lite4', 'efficientnet_v2_b0', 'efficientnet_v2_b1', 'efficientnet_v2_b2', 'efficientnet_v2_b3', 'efficientnet_v2_l', 'efficientnet_v2_l_in21ft1k', 'efficientnet_v2_l_in21k', 'efficientnet_v2_m', 'efficientnet_v2_m_in21ft1k', 'efficientnet_v2_m_in21k', 'efficientnet_v2_s', 'efficientnet_v2_s_in21ft1k', 'efficientnet_v2_s_in21k', 'efficientnet_v2_xl_in21ft1k', 'efficientnet_v2_xl_in21k', 'gmixer_12_224', 'gmixer_24_224', 'gmlp_b16_224', 'gmlp_s16_224', 'gmlp_ti16_224', 'ig_resnext101_32x8d', 'ig_resnext101_32x16d', 'ig_resnext101_32x32d', 'ig_resnext101_32x48d', 'mixer_b16_224', 'mixer_b16_224_in21k', 'mixer_b16_224_miil', 'mixer_b16_224_miil_in21k', 'mixer_b32_224', 'mixer_l16_224', 'mixer_l16_224_in21k', 'mixer_l32_224', 'mixer_s16_224', 'mixer_s32_224', 'mobilenet_v2_050', 'mobilenet_v2_100', 'mobilenet_v2_110d', 'mobilenet_v2_120d', 'mobilenet_v2_140', 'pit_b_224', 'pit_b_distilled_224', 'pit_s_224', 'pit_s_distilled_224', 'pit_ti_224', 'pit_ti_distilled_224', 'pit_xs_224', 'pit_xs_distilled_224', 'poolformer_m36', 'poolformer_m48', 'poolformer_s12', 'poolformer_s24', 'poolformer_s36', 'pt_efficientnet_b0', 'pt_efficientnet_b1', 'pt_efficientnet_b2', 'pt_efficientnet_b3', 'pt_efficientnet_b4', 'pvt_large', 'pvt_medium', 'pvt_small', 'pvt_tiny', 'pvt_v2_b0', 'pvt_v2_b1', 'pvt_v2_b2', 'pvt_v2_b3', 'pvt_v2_b4', 'pvt_v2_b5', 'resmlp_12_224', 'resmlp_12_224_dino', 'resmlp_12_distilled_224', 'resmlp_24_224', 'resmlp_24_224_dino', 'resmlp_24_distilled_224', 'resmlp_36_224', 'resmlp_36_distilled_224', 'resmlp_big_24_224', 'resmlp_big_24_224_in22ft1k', 'resmlp_big_24_distilled_224', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet26t', 'resnet34', 'resnet34d', 'resnet50', 'resnet50_gn', 'resnet50d', 'resnet101', 'resnet101d', 'resnet152', 'resnet152d', 'resnet200d', 'resnetblur50', 'resnetrs50', 'resnetrs101', 'resnetrs152', 'resnetrs200', 'resnetrs270', 'resnetrs350', 'resnetrs420', 'resnetv2_50x1_bit_distilled', 'resnetv2_50x1_bitm', 'resnetv2_50x1_bitm_in21k', 'resnetv2_50x3_bitm', 'resnetv2_50x3_bitm_in21k', 'resnetv2_101x1_bitm', 'resnetv2_101x1_bitm_in21k', 'resnetv2_101x3_bitm', 'resnetv2_101x3_bitm_in21k', 'resnetv2_152x2_bit_teacher', 'resnetv2_152x2_bit_teacher_384', 'resnetv2_152x2_bitm', 'resnetv2_152x2_bitm_in21k', 'resnetv2_152x4_bitm', 'resnetv2_152x4_bitm_in21k', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x8d', 'seresnet50', 'seresnet152d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext50_32x4d', 'ssl_resnet18', 'ssl_resnet50', 'ssl_resnext50_32x4d', 'ssl_resnext101_32x4d', 'ssl_resnext101_32x8d', 'ssl_resnext101_32x16d', 'swin_base_patch4_window7_224', 'swin_base_patch4_window7_224_in22k', 'swin_base_patch4_window12_384', 'swin_base_patch4_window12_384_in22k', 'swin_large_patch4_window7_224', 'swin_large_patch4_window7_224_in22k', 'swin_large_patch4_window12_384', 'swin_large_patch4_window12_384_in22k', 'swin_small_patch4_window7_224', 'swin_tiny_patch4_window7_224', 'swsl_resnet18', 'swsl_resnet50', 'swsl_resnext50_32x4d', 'swsl_resnext101_32x4d', 'swsl_resnext101_32x8d', 'swsl_resnext101_32x16d', 'tv_resnet34', 'tv_resnet50', 'tv_resnet101', 'tv_resnet152', 'tv_resnext50_32x4d', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'vit_base_patch8_224', 'vit_base_patch8_224_in21k', 'vit_base_patch16_224', 'vit_base_patch16_224_in21k', 'vit_base_patch16_224_miil', 'vit_base_patch16_224_miil_in21k', 'vit_base_patch16_384', 'vit_base_patch16_sam_224', 'vit_base_patch32_224', 'vit_base_patch32_224_in21k', 'vit_base_patch32_384', 'vit_base_patch32_sam_224', 'vit_base_r50_s16_224_in21k', 'vit_base_r50_s16_384', 'vit_huge_patch14_224_in21k', 'vit_large_patch16_224', 'vit_large_patch16_224_in21k', 'vit_large_patch16_384', 'vit_large_patch32_224', 'vit_large_patch32_224_in21k', 'vit_large_patch32_384', 'vit_large_r50_s32_224', 'vit_large_r50_s32_224_in21k', 'vit_large_r50_s32_384', 'vit_small_patch16_224', 'vit_small_patch16_224_in21k', 'vit_small_patch16_384', 'vit_small_patch32_224', 'vit_small_patch32_224_in21k', 'vit_small_patch32_384', 'vit_small_r26_s32_224', 'vit_small_r26_s32_224_in21k', 'vit_small_r26_s32_384', 'vit_tiny_patch16_224', 'vit_tiny_patch16_224_in21k', 'vit_tiny_patch16_384', 'vit_tiny_r_s16_p8_224', 'vit_tiny_r_s16_p8_224_in21k', 'vit_tiny_r_s16_p8_384', 'wide_resnet50_2', 'wide_resnet101_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the opt object with the necessary attributes\n",
        "class Options:\n",
        "    def __init__(self):\n",
        "        self.nb_classes = 10  # Set the number of classes as needed\n",
        "\n",
        "opt = Options()\n",
        "\n",
        "\n",
        "import tfimm\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create the model\n",
        "import tfimm\n",
        "from models_vit import *\n",
        "# call the model\n",
        "vit_model = tfimm.create_model(\n",
        "    \"vit_large_patch16_224\",\n",
        "    nb_classes=1000 )\n",
        "# Path to the custom weights\n",
        "retfound_weights_path = \"/content/drive/MyDrive/Colab/CFUN/RETFound_oct_weights.h5\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0CgPS8jhRka_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the custom weights\n",
        "vit_model.load_weights(retfound_weights_path)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i-xs_-WnRy_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8VHnW06EgQK",
        "outputId": "ea5130d3-396c-4d06-c88e-848a67a85070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vit_large_patch16_224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " patch_embed (PatchEmbedding  multiple                 787456    \n",
            " s)                                                              \n",
            "                                                                 \n",
            " dropout_582 (Dropout)       multiple                  0         \n",
            "                                                                 \n",
            " blocks/0 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/1 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/2 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/3 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/4 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/5 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/6 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/7 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/8 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/9 (ViTBlock)         multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/10 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/11 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/12 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/13 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/14 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/15 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/16 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/17 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/18 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/19 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/20 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/21 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/22 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " blocks/23 (ViTBlock)        multiple                  12596224  \n",
            "                                                                 \n",
            " norm (LayerNormalization)   multiple                  2048      \n",
            "                                                                 \n",
            " head (Dense)                multiple                  1025000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 304,326,632\n",
            "Trainable params: 304,326,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vit_model.load_weights(retfound_weights_path, by_name=True, skip_mismatch=True)\n"
      ],
      "metadata": {
        "id": "2WE1aiMzG7YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tfimm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Concatenate, Input, Reshape, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "metadata": {
        "id": "sL5Peb7EGxzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the weights of the layer with mismatched shape\n",
        "weights = vit_model.get_layer(\"head\").get_weights()\n",
        "\n",
        "# Adjust the shape of the weights\n",
        "new_weights = np.random.normal(size=(1024, 1000))  # Adjust the shape as needed\n",
        "weights[0] = new_weights\n",
        "\n",
        "# Set the new weights back to the layer\n",
        "vit_model.get_layer(\"head\").set_weights(weights)\n"
      ],
      "metadata": {
        "id": "ck92NdBNLNoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vit_model.layers:\n",
        "    layer.trainable = False\n",
        "vit_model.layers[-1].trainable = True  # Unfreeze the last layer\n"
      ],
      "metadata": {
        "id": "GYVfRRWfI_Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tfimm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Concatenate, Input, Reshape, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Create the ViT model with pre-trained weights\n",
        "vit_model = tfimm.create_model(\n",
        "    \"vit_large_patch16_224\",\n",
        "    nb_classes=1000  # Load pre-trained weights for 1000 classes\n",
        ")\n",
        "\n",
        "# Load the pre-trained weights\n",
        "retfound_weights_path = \"/content/drive/MyDrive/Colab/CFUN/RETFound_oct_weights.h5\"\n",
        "vit_model.load_weights(retfound_weights_path)\n",
        "\n",
        "# Freeze the layers except the last one\n",
        "for layer in vit_model.layers:\n",
        "    layer.trainable = False\n",
        "vit_model.layers[-1].trainable = True  # Unfreeze the last layer\n",
        "\n",
        "# Extract the encoder part of the ViT model\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "vit_output = vit_model(input_tensor)\n",
        "\n",
        "# Use the output from the last transformer block\n",
        "encoder_output = vit_model.get_layer(\"norm\").output\n",
        "encoder = Model(inputs=input_tensor, outputs=encoder_output)\n",
        "\n",
        "# Define the U-Net decoder\n",
        "def unet_decoder(encoder_output, num_classes):\n",
        "    x = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(encoder_output)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(num_classes, (1, 1), activation='sigmoid')(x)\n",
        "    return x\n",
        "\n",
        "# Combine the encoder and decoder to form the U-Net\n",
        "decoder_output = unet_decoder(encoder_output, num_classes=1)\n",
        "unet_model = Model(inputs=input_tensor, outputs=decoder_output)\n",
        "\n",
        "# Compile the U-Net model\n",
        "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "j_hIIMzFJAom",
        "outputId": "ffd8bb2e-678d-4b9a-cf2e-462ff347b0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Layer norm has no inbound nodes.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-02eb1f5f2aeb>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Use the output from the last transformer block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"norm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2167\u001b[0m     \"\"\"\n\u001b[1;32m   2168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2169\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Layer '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' has no inbound nodes.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2170\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_tensors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Layer norm has no inbound nodes."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "vit_output = vit_model(input_tensor)\n",
        "\n",
        "#\n"
      ],
      "metadata": {
        "id": "ALzb4PHyBE8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_decoder(encoder_output, num_classes):\n",
        "    x = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(encoder_output)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(num_classes, (1, 1), activation='sigmoid')(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "UkSGQLd4FLFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "encoder_output = encoder(input_tensor)\n",
        "decoder_output = unet_decoder(encoder_output, num_classes=1)\n",
        "\n",
        "unet_model = Model(inputs=input_tensor, outputs=decoder_output)\n"
      ],
      "metadata": {
        "id": "4y7NgF0TFNsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "c25CCF0CFPxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def unet_model(input_size=(256, 256, 1)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    # Bottleneck\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "\n",
        "    # Decoder\n",
        "    u4 = layers.UpSampling2D((2, 2))(c3)\n",
        "    u4 = layers.concatenate([u4, c2])\n",
        "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u4)\n",
        "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    u5 = layers.UpSampling2D((2, 2))(c4)\n",
        "    u5 = layers.concatenate([u5, c1])\n",
        "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u5)\n",
        "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = unet_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGk01RXHezDv",
        "outputId": "cd83339a-f1ec-4e41-d3d8-2fba5171e470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  640         ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 128, 128, 25  0           ['conv2d_5[0][0]']               \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128, 128, 38  0           ['up_sampling2d[0][0]',          \n",
            "                                4)                                'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 128, 12  442496      ['concatenate[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_6[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_7[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_1[0][0]',        \n",
            "                                2)                                'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 256, 256, 64  110656      ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d_8[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 256, 256, 1)  65          ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,881,985\n",
            "Trainable params: 1,881,985\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the pre-trained ViT model\n",
        "vit_model = tf.keras.applications.vit_large_patch16_224(weights='imagenet', include_top=False)\n",
        "\n",
        "# Freeze all layers except the last one\n",
        "for layer in vit_model.layers:\n",
        "    layer.trainable = False\n",
        "vit_model.layers[-1].trainable = True  # Unfreeze the last layer if needed\n",
        "\n",
        "# Function to build U-Net with ViT encoder\n",
        "def build_unet_with_vit_encoder(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = vit_model(inputs)\n",
        "\n",
        "    # U-Net decoder layers\n",
        "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Build the U-Net model with ViT encoder\n",
        "input_shape = (224, 224, 3)\n",
        "unet_model = build_unet_with_vit_encoder(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the new model\n",
        "unet_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8zBx3-edNq9X",
        "outputId": "e4c6904c-5667-4482-ff4c-be641ffe2909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'keras.api._v2.keras.applications' has no attribute 'vit_large_patch16_224'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-aacff41872f7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the pre-trained ViT model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvit_large_patch16_224\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Freeze all layers except the last one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.applications' has no attribute 'vit_large_patch16_224'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cpkS6w7xeyBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, LayerNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Assuming you have 'retfound_encoder' from the previous steps\n",
        "# Example: retfound_encoder = load_retfound_weights()\n",
        "\n",
        "# Define the U-Net architecture\n",
        "def build_unet(input_shape, num_classes):\n",
        "    # Encoder (using RETFound weights)\n",
        "    encoder_output = retfound_encoder.get_layer('output_layer_name').output\n",
        "\n",
        "    # Decoder\n",
        "    x = UpSampling2D(size=(2, 2))(encoder_output)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)  # Add more decoder layers as needed\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "    # Final segmentation output\n",
        "    segmentation_output = Conv2D(num_classes, (1, 1), activation='sigmoid')(x)  # Binary segmentation\n",
        "\n",
        "    # Create the U-Net model\n",
        "    unet_model = Model(inputs=retfound_encoder.input, outputs=segmentation_output)\n",
        "\n",
        "    # Freeze the last layer (output layer) of the encoder\n",
        "    last_layer = retfound_encoder.get_layer('output_layer_name')\n",
        "    last_layer.trainable = False\n",
        "\n",
        "    return unet_model\n",
        "\n",
        "# Load RETFound weights (replace with actual path)\n",
        "retfound_encoder = tf.keras.models.load_model('/content/drive/MyDrive/Colab/CFUN/retfound_encoder.h5')\n",
        "retfound_encoder.load_weights('/content/drive/MyDrive/Colab/CFUN/weights.pth')\n",
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (256, 256, 3)  # Replace with your image dimensions\n",
        "num_classes = 1  # Binary segmentation (choroid present or not)\n",
        "\n",
        "# Create U-Net model\n",
        "unet_model = build_unet(input_shape, num_classes)\n",
        "\n",
        "# Compile the model (use binary cross-entropy for binary segmentation)\n",
        "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 8  # Replace with your desired batch size\n",
        "\n",
        "# Generate dummy data (replace with your data)\n",
        "dummy_input = tf.random.normal((batch_size, input_shape[0], input_shape[1], input_shape[2]))\n",
        "dummy_mask = tf.random.uniform((batch_size, input_shape[0], input_shape[1], num_classes), minval=0, maxval=1)\n",
        "\n",
        "# Train the model (optional)\n",
        "unet_model.fit(dummy_input, dummy_mask, epochs=10, batch_size=batch_size)\n",
        "\n",
        "print(\"U-Net with RETFound encoder and decoder successfully implemented!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "bnFYgacYU8MT",
        "outputId": "35246fa1-cab3-4925-e98b-5b0fe88047a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No file or directory found at /content/drive/MyDrive/Colab/CFUN/retfound_encoder.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b9a34a617f69>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Load RETFound weights (replace with actual path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mretfound_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab/CFUN/retfound_encoder.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mretfound_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab/CFUN/weights.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /content/drive/MyDrive/Colab/CFUN/retfound_encoder.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W660D8K1MfQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import models_vit\n",
        "from util.pos_embed import interpolate_pos_embed\n",
        "from timm.models.layers import trunc_normal_\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# call the model\n",
        "retfound_model = models_vit.__dict__['vit_large_patch16'](\n",
        "    num_classes=2,\n",
        "    drop_path_rate=0.2,\n",
        "    global_pool=True,\n",
        ")\n",
        "\n",
        "# load RETFound weights\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Colab/CFUN/weights.pth', map_location=device)\n",
        "checkpoint_model = checkpoint['model']\n",
        "state_dict = retfound_model.state_dict()\n",
        "for k in ['head.weight', 'head.bias']:\n",
        "    if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
        "        print(f\"Removing key {k} from pretrained checkpoint\")\n",
        "        del checkpoint_model[k]\n",
        "\n",
        "# interpolate position embedding\n",
        "interpolate_pos_embed(retfound_model, checkpoint_model)\n",
        "\n",
        "# load pre-trained model\n",
        "msg = retfound_model.load_state_dict(checkpoint_model, strict=False)\n",
        "\n",
        "assert set(msg.missing_keys) == {'head.weight', 'head.bias', 'fc_norm.weight', 'fc_norm.bias'}\n",
        "\n",
        "# manually initialize fc layer\n",
        "trunc_normal_(retfound_model.head.weight, std=2e-5)\n",
        "\n"
      ],
      "metadata": {
        "id": "W_ScGHW5dhyr",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc8ca7b3-f242-4e3d-cb2b-08ecd59af9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 3.7260e-05, -1.3732e-05,  2.4529e-06,  ..., -1.6099e-05,\n",
              "         -1.2859e-05, -3.8157e-05],\n",
              "        [ 7.5534e-06,  1.9484e-05, -2.0839e-05,  ..., -2.0702e-05,\n",
              "         -2.7611e-05, -1.3252e-05]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from RETFound_MAE.models_vit import vit_large_patch16\n",
        "\n",
        "# Define the U-Net model\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super(UNet, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.encoder.head = nn.Identity()  # Remove the classification head\n",
        "        self.encoder.blocks[-1].requires_grad_(False)  # Freeze the last layer of the encoder\n",
        "\n",
        "        # Define the decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), 1024, 14, 14)  # Reshape for the decoder\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "encoder = vit_large_patch16(num_classes=2, drop_path_rate=0.2, global_pool=True)\n",
        "model = UNet(encoder)\n",
        "\n",
        "# Dummy input to test the model\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "output = model(dummy_input)\n",
        "print(output.shape)  # Should print torch.Size([1, 1, 224, 224])\n"
      ],
      "metadata": {
        "id": "PaBoDsH_eNSu",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "acdb4a8b-7b3a-4d79-a717-838b6decbcac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Unknown pool type True",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4430e4a34c89>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Dummy input to test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Should print torch.Size([1, 1, 224, 224])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-4430e4a34c89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape for the decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward_head\u001b[0;34m(self, x, pre_logits)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_logits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mpool\u001b[0;34m(self, x, pool_type)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0mpool_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_pool\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpool_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_pool_nlc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_prefix_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_prefix_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mglobal_pool_nlc\u001b[0;34m(x, pool_type, num_prefix_tokens, reduce_include_prefix)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Unknown pool type {pool_type}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Unknown pool type True"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "\n",
        "# Source directories\n",
        "source_images = '/content/drive/MyDrive/Colab/data'\n",
        "source_masks = '/content/drive/MyDrive/Colab/mask'\n",
        "\n",
        "# Destination directories\n",
        "dest_images = '/content/data/images/'\n",
        "dest_masks = '/content/data/masks/'\n",
        "\n",
        "# Create destination directories if they don't exist\n",
        "os.makedirs(dest_images, exist_ok=True)\n",
        "os.makedirs(dest_masks, exist_ok=True)\n",
        "\n",
        "# Copy only the first 50 images and corresponding masks\n",
        "image_files = os.listdir(source_images)[:50]\n",
        "for file_name in image_files:\n",
        "    # Convert the file extension to lowercase to handle both .jpg and .JPG, .tif and .TIF\n",
        "    file_ext = file_name.lower()\n",
        "\n",
        "    # Check if the file is either .jpg or .tif\n",
        "    if file_ext.endswith('.jpg') or file_ext.endswith('.tif'):\n",
        "        image_path = os.path.join(source_images, file_name)\n",
        "\n",
        "        # Construct the corresponding mask filename\n",
        "        # Replace only if the file is .jpg; for .tif, use the original extension\n",
        "        if file_ext.endswith('.jpg'):\n",
        "            mask_file_name = file_name.replace('.jpg', '_mask.png').replace('.JPG', '_mask.png')\n",
        "        elif file_ext.endswith('.tif'):\n",
        "            mask_file_name = file_name.replace('.tif', '_mask.png').replace('.TIF', '_mask.png')\n",
        "\n",
        "        mask_path = os.path.join(source_masks, mask_file_name)\n",
        "\n",
        "        if os.path.exists(image_path) and os.path.exists(mask_path):\n",
        "            copyfile(image_path, os.path.join(dest_images, file_name))\n",
        "            copyfile(mask_path, os.path.join(dest_masks, mask_file_name))\n",
        "        else:\n",
        "            print(f\"Missing file: {file_name} or {mask_file_name}\")\n"
      ],
      "metadata": {
        "id": "THn8_ebZleby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 8\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 10\n",
        "\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Transformations for images with normalization\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
        "    transforms.ToTensor(),  # Convert the image to a tensor\n",
        "    transforms.Normalize(mean=mean, std=std)  # Normalize the tensor\n",
        "])\n",
        "\n",
        "# Transformations for masks (no normalization needed)\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the mask to 224x224 to match the image size\n",
        "    transforms.ToTensor(),  # Convert the mask to a tensor\n",
        "])\n",
        "# Custom Dataset\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, image_transform=None, mask_transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "        self.image_files = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_file = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_file)\n",
        "\n",
        "        # Replace image file extension with corresponding mask extension\n",
        "        if img_file.lower().endswith('.jpg'):\n",
        "            mask_file = img_file.replace('.jpg', '_mask.png').replace('.JPG', '_mask.png')\n",
        "        elif img_file.lower().endswith('.tif'):\n",
        "            mask_file = img_file.replace('.tif', '_mask.png').replace('.TIF', '_mask.png')\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {img_file}\")\n",
        "\n",
        "        mask_path = os.path.join(self.mask_dir, mask_file)\n",
        "\n",
        "        # Open image and mask\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Datasets and Dataloaders\n",
        "train_dataset = SegmentationDataset(image_dir='/content/data/images/', mask_dir='/content/data/masks/', image_transform=image_transform, mask_transform=mask_transform)\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = UNet(in_channels=3, out_channels=1).to(device)\n",
        "\n",
        "# Freeze the last layer of the encoder (replace 'encoder[-1]' with the correct attribute)\n",
        "# Make sure this is the correct way to reference the encoder layers\n",
        "# Freeze the last block in the encoder\n",
        "#for param in model.blocks[-1].parameters():\n",
        " #   param.requires_grad = False\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
        "\n",
        "# Training loop with evaluation\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (images, masks) in enumerate(train_loader):\n",
        "        images = images.to(device).float()\n",
        "        masks = masks.to(device).float()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Calculate average training loss\n",
        "    avg_train_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "    # Evaluation phase\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():  # Disable gradient computation during evaluation\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device).float()\n",
        "            masks = masks.to(device).float()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    # Calculate average validation loss\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
        "          f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "print(\"Training and Evaluation Completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "IbLMksP4pAe4",
        "outputId": "fbccd26d-4427-4684-cd75-1a94199bb903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Unknown pool type True",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ec6316a5167e>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3beb644c0873>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward_head\u001b[0;34m(self, x, pre_logits)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_logits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mpool\u001b[0;34m(self, x, pool_type)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0mpool_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_pool\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpool_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_pool_nlc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_prefix_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_prefix_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mglobal_pool_nlc\u001b[0;34m(x, pool_type, num_prefix_tokens, reduce_include_prefix)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Unknown pool type {pool_type}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Unknown pool type True"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ve6xPVfop1AC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}