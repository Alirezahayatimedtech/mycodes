{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 4289678,
          "sourceType": "datasetVersion",
          "datasetId": 2527538
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alirezahayatimedtech/mycodes/blob/main/diabetes_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'diabetes-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2527538%2F4289678%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240320%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240320T035322Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6d15c26bf921586c6449d85bc006f6229065798638aa9687fc8a9e27016f224a3e284c5fb946ef2eac80a525cf2293d843855ee151932eee0327d805c7f7753497e26b2bf99c44729fc785f0a40ca6483402ef6f30a9c22a73fcb75613ef1f6ff8f6ad8b4a70ba6295e1e9308495089a556cd0190ba52193c9c8e84c4513d95d977b9a2506ba2b0e2d532f13f00873a527cc666ca4bb3b0b9be8fbfb0c9d5054eecf12c0a6eab49311bd9131e06149338e9ddbf043d70f3271ec9cbd829b7f559c0c0bc7ed4a74ca80e62b46c46158d20e99e5c648d8f310a1ef6f4f7184a0a315d6e622d09fc3c9ee0a385d4acbc207478681bcc08140f3a005a237b5b3bace'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Tt4YXP44_ikI"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input/diabetes-dataset'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-20T03:45:11.54368Z",
          "iopub.execute_input": "2024-03-20T03:45:11.544384Z",
          "iopub.status.idle": "2024-03-20T03:45:13.03339Z",
          "shell.execute_reply.started": "2024-03-20T03:45:11.544346Z",
          "shell.execute_reply": "2024-03-20T03:45:13.032058Z"
        },
        "id": "2_3xv9ag_ikO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/kaggle/input/diabetes-dataset/diabetes.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T15:01:17.92193Z",
          "iopub.execute_input": "2024-03-19T15:01:17.92336Z",
          "iopub.status.idle": "2024-03-19T15:01:17.933414Z",
          "shell.execute_reply.started": "2024-03-19T15:01:17.923319Z",
          "shell.execute_reply": "2024-03-19T15:01:17.932067Z"
        },
        "trusted": true,
        "id": "SsBgp2NW_ikQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:06:26.945344Z",
          "iopub.execute_input": "2024-03-19T10:06:26.945761Z",
          "iopub.status.idle": "2024-03-19T10:06:26.955547Z",
          "shell.execute_reply.started": "2024-03-19T10:06:26.945731Z",
          "shell.execute_reply": "2024-03-19T10:06:26.954225Z"
        },
        "trusted": true,
        "id": "8KFqX8w8_ikR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "print(\"Setup Complete\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T15:01:21.182425Z",
          "iopub.execute_input": "2024-03-19T15:01:21.182873Z",
          "iopub.status.idle": "2024-03-19T15:01:21.192617Z",
          "shell.execute_reply.started": "2024-03-19T15:01:21.182838Z",
          "shell.execute_reply": "2024-03-19T15:01:21.190451Z"
        },
        "trusted": true,
        "id": "Q-xJXqEt_ikR",
        "outputId": "7fb7734d-34dc-4af1-c6f2-10e2ca1991bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Setup Complete\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-18T19:04:49.2063Z",
          "iopub.execute_input": "2024-03-18T19:04:49.206794Z",
          "iopub.status.idle": "2024-03-18T19:04:49.223405Z",
          "shell.execute_reply.started": "2024-03-18T19:04:49.206751Z",
          "shell.execute_reply": "2024-03-18T19:04:49.221919Z"
        },
        "trusted": true,
        "id": "AObYTYL2_ikU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fit the model on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict the outcomes on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy of the logistic regression model: {accuracy:.2f}')\n",
        "print('Classification Report:')\n",
        "print(report)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T13:54:45.132325Z",
          "iopub.execute_input": "2024-03-19T13:54:45.132823Z",
          "iopub.status.idle": "2024-03-19T13:54:45.498291Z",
          "shell.execute_reply.started": "2024-03-19T13:54:45.132787Z",
          "shell.execute_reply": "2024-03-19T13:54:45.497054Z"
        },
        "trusted": true,
        "id": "QLh4xfvc_ikV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the models\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'LogReg' : LogisticRegression()\n",
        "}\n",
        "\n",
        "# Fit the models and print the accuracy\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    print(f'{name} Model Accuracy: {accuracy:.2f}')\n",
        "    print(f'{name} Classification Report:')\n",
        "    print(report)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:06:38.858011Z",
          "iopub.execute_input": "2024-03-19T10:06:38.859145Z",
          "iopub.status.idle": "2024-03-19T10:06:39.438772Z",
          "shell.execute_reply.started": "2024-03-19T10:06:38.859099Z",
          "shell.execute_reply": "2024-03-19T10:06:39.437554Z"
        },
        "trusted": true,
        "id": "itbCraJk_ikY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Assuming you have already split your data and trained your models\n",
        "# models dictionary should be defined as before with trained models\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.xticks(np.arange(len(classes)), classes)\n",
        "    plt.yticks(np.arange(len(classes)), classes)\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(fpr, tpr, roc_auc, model_name):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'Receiver operating characteristic - {model_name}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Plotting confusion matrix and ROC curve for each model\n",
        "for name, model in models.items():\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, model.predict(X_test))\n",
        "    plot_confusion_matrix(cm, classes=['Non-Diabetic', 'Diabetic'], title=f'{name} Confusion Matrix')\n",
        "\n",
        "    # ROC curve\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_score = model.predict_proba(X_test)[:, 1]\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plot_roc_curve(fpr, tpr, roc_auc, name)\n",
        "    else:\n",
        "        print(f\"{name} model does not support probability estimates and cannot plot ROC curve.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:06:53.828054Z",
          "iopub.execute_input": "2024-03-19T10:06:53.828494Z",
          "iopub.status.idle": "2024-03-19T10:06:57.259231Z",
          "shell.execute_reply.started": "2024-03-19T10:06:53.828446Z",
          "shell.execute_reply": "2024-03-19T10:06:57.258086Z"
        },
        "trusted": true,
        "id": "PpRfGDrf_ikZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "for name, model in models.items():\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_score = model.predict_proba(X_test)[:, 1]\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(recall, precision, label=f'{name}')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision-Recall Curve')\n",
        "        plt.legend(loc=\"lower left\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:07:14.775407Z",
          "iopub.execute_input": "2024-03-19T10:07:14.775955Z",
          "iopub.status.idle": "2024-03-19T10:07:16.518428Z",
          "shell.execute_reply.started": "2024-03-19T10:07:14.775914Z",
          "shell.execute_reply": "2024-03-19T10:07:16.517347Z"
        },
        "trusted": true,
        "id": "m3EuLxVX_ika"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    model, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5))\n",
        "\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.xlabel(\"Training examples\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title('Learning Curves')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:07:24.821717Z",
          "iopub.execute_input": "2024-03-19T10:07:24.822142Z",
          "iopub.status.idle": "2024-03-19T10:07:27.5399Z",
          "shell.execute_reply.started": "2024-03-19T10:07:24.82211Z",
          "shell.execute_reply": "2024-03-19T10:07:27.538576Z"
        },
        "trusted": true,
        "id": "IP31HWjG_ika"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate a simple plot of the test and training learning curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features)\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "    axes : axes object, optional (default=None)\n",
        "        Axes object to plot on.\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 5-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - An object to be used as a cross-validation generator.\n",
        "          - An iterable yielding train/test splits.\n",
        "    n_jobs : int or None, optional (default=None)\n",
        "        Number of jobs to run in parallel.\n",
        "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the dtype is float, it is regarded as a\n",
        "        fraction of the maximum size of the training set (that is determined\n",
        "        by the selected validation method), i.e. it has to be within (0, 1].\n",
        "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
        "    \"\"\"\n",
        "    if axes is None:\n",
        "        _, axes = plt.subplots(1, 1, figsize=(20, 5))\n",
        "\n",
        "    axes.set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes.set_ylim(*ylim)\n",
        "    axes.set_xlabel(\"Training examples\")\n",
        "    axes.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes,\n",
        "                       return_times=True)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes.grid()\n",
        "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                      train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                      color=\"r\")\n",
        "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                      test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                      color=\"g\")\n",
        "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "              label=\"Training score\")\n",
        "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "              label=\"Cross-validation score\")\n",
        "    axes.legend(loc=\"best\")\n",
        "\n",
        "    return plt\n",
        "\n",
        "# Example of plotting learning curves for all models\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
        "for i, (name, model) in enumerate(models.items()):\n",
        "    ax = axes.flatten()[i]\n",
        "    plot_learning_curve(model, f'Learning Curve for {name}', X, y, axes=ax, ylim=(0.7, 1.01), cv=5, n_jobs=4)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:07:34.765209Z",
          "iopub.execute_input": "2024-03-19T10:07:34.766078Z",
          "iopub.status.idle": "2024-03-19T10:07:40.84697Z",
          "shell.execute_reply.started": "2024-03-19T10:07:34.766033Z",
          "shell.execute_reply": "2024-03-19T10:07:40.846063Z"
        },
        "trusted": true,
        "id": "dWG-W9b4_ika"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "# Assuming 'X_test' is your test set and 'model' is one of your trained models\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=['Negative', 'Positive'], discretize_continuous=True)\n",
        "\n",
        "# Choose an instance to explain\n",
        "i = 10  # Index of the instance you want to explain\n",
        "exp = explainer.explain_instance(X_test.values[i], model.predict_proba, num_features=5)\n",
        "exp.show_in_notebook(show_table=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:08:07.095211Z",
          "iopub.execute_input": "2024-03-19T10:08:07.095721Z",
          "iopub.status.idle": "2024-03-19T10:08:07.648432Z",
          "shell.execute_reply.started": "2024-03-19T10:08:07.095685Z",
          "shell.execute_reply": "2024-03-19T10:08:07.646811Z"
        },
        "trusted": true,
        "id": "4AQpfsLF_ikb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Assuming 'X_train' is your training set and 'model' is one of your trained models\n",
        "explainer = shap.TreeExplainer(models['Random Forest'])\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "# Plot summary plot using SHAP values\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:08:15.836437Z",
          "iopub.execute_input": "2024-03-19T10:08:15.83687Z",
          "iopub.status.idle": "2024-03-19T10:08:23.505942Z",
          "shell.execute_reply.started": "2024-03-19T10:08:15.836836Z",
          "shell.execute_reply": "2024-03-19T10:08:23.504564Z"
        },
        "trusted": true,
        "id": "baDtYBEF_ikb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Assuming 'X_train' is your training set and 'model' is one of your trained models\n",
        "explainer = shap.TreeExplainer(models['Decision Tree'])\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "# Plot summary plot using SHAP values\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-18T20:16:58.403359Z",
          "iopub.execute_input": "2024-03-18T20:16:58.403951Z",
          "iopub.status.idle": "2024-03-18T20:16:58.741554Z",
          "shell.execute_reply.started": "2024-03-18T20:16:58.403908Z",
          "shell.execute_reply": "2024-03-18T20:16:58.740216Z"
        },
        "trusted": true,
        "id": "RJQRgAkQ_ikc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-18T20:15:56.983785Z",
          "iopub.execute_input": "2024-03-18T20:15:56.984224Z",
          "iopub.status.idle": "2024-03-18T20:15:56.993109Z",
          "shell.execute_reply.started": "2024-03-18T20:15:56.984192Z",
          "shell.execute_reply": "2024-03-18T20:15:56.99193Z"
        },
        "trusted": true,
        "id": "_ltMYuvm_ikc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have a dictionary 'models' with your trained models\n",
        "# And 'accuracy_score' function has been used to calculate accuracies\n",
        "\n",
        "# Dictionary to hold model names and their corresponding accuracies\n",
        "model_accuracies = {}\n",
        "\n",
        "# Calculate accuracies for each model and store them in the dictionary\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    model_accuracies[name] = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Data for plotting\n",
        "model_names = list(model_accuracies.keys())\n",
        "accuracies = list(model_accuracies.values())\n",
        "\n",
        "# Plotting the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(model_names, accuracies, color='skyblue')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Model Accuracies')\n",
        "plt.ylim([0, 1])  # Accuracy ranges from 0 to 1\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()  # Adjusts plot to ensure everything fits without overlapping\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:08:32.905782Z",
          "iopub.execute_input": "2024-03-19T10:08:32.906393Z",
          "iopub.status.idle": "2024-03-19T10:08:33.30357Z",
          "shell.execute_reply.started": "2024-03-19T10:08:32.906357Z",
          "shell.execute_reply": "2024-03-19T10:08:33.302231Z"
        },
        "trusted": true,
        "id": "1QnXgu-7_ikc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-18T19:39:13.843189Z",
          "iopub.execute_input": "2024-03-18T19:39:13.843565Z",
          "iopub.status.idle": "2024-03-18T19:39:13.907643Z",
          "shell.execute_reply.started": "2024-03-18T19:39:13.843536Z",
          "shell.execute_reply": "2024-03-18T19:39:13.904627Z"
        },
        "trusted": true,
        "id": "qVU1u_ra_ikc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'df' is your dataframe and 'models' is a dictionary with your trained models\n",
        "\n",
        "# Get feature names from the dataframe\n",
        "feature_names = df.drop('Outcome', axis=1).columns\n",
        "\n",
        "# Function to plot feature importances\n",
        "def plot_feature_importances(importances, model_name):\n",
        "    indices = np.argsort(importances)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(f'Feature Importances in {model_name}')\n",
        "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel('Relative Importance')\n",
        "    plt.show()\n",
        "\n",
        "# Random Forest feature importances\n",
        "if 'Random Forest' in models:\n",
        "    rf_importances = models['Random Forest'].feature_importances_\n",
        "    plot_feature_importances(rf_importances, 'Random Forest')\n",
        "\n",
        "# Decision Tree feature importances\n",
        "if 'Decision Tree' in models:\n",
        "    dt_importances = models['Decision Tree'].feature_importances_\n",
        "    plot_feature_importances(dt_importances, 'Decision Tree')\n",
        "\n",
        "# For models like Logistic Regression, SVM, and Naive Bayes, we can look at the coefficients\n",
        "# Note: SVM and Naive Bayes may require different handling depending on the kernel and model type\n",
        "\n",
        "if 'Logistic Regression' in models:\n",
        "    lr_coefs = models['Logistic Regression'].coef_[0]\n",
        "    plot_feature_importances(lr_coefs, 'Logistic Regression')\n",
        "\n",
        "# Note: KNN does not provide feature importances as it is a non-parametric method.\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:08:41.196832Z",
          "iopub.execute_input": "2024-03-19T10:08:41.197255Z",
          "iopub.status.idle": "2024-03-19T10:08:41.802515Z",
          "shell.execute_reply.started": "2024-03-19T10:08:41.197222Z",
          "shell.execute_reply": "2024-03-19T10:08:41.801217Z"
        },
        "trusted": true,
        "id": "D8c_ZWyP_ikd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'model_metrics' is a dictionary with your calculated metrics for each model\n",
        "\n",
        "# Data for plotting\n",
        "n_groups = len(model_metrics)\n",
        "index = np.arange(n_groups)\n",
        "bar_width = 0.2\n",
        "\n",
        "# Find the minimum score to set as the lower limit for the y-axis\n",
        "min_scores = {metric: min([metrics[metric] for metrics in model_metrics.values()]) for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score']}\n",
        "min_score = min(min_scores.values())\n",
        "\n",
        "# Plotting each metric\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "for i, metric in enumerate(['Accuracy', 'Precision', 'Recall', 'F1 Score']):\n",
        "    values = [model_metrics[model][metric] for model in model_metrics]\n",
        "    ax.bar(index + i * bar_width, values, bar_width, label=metric)\n",
        "\n",
        "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Comparison of Model Metrics')\n",
        "ax.set_xticks(index + bar_width / 2)\n",
        "ax.set_xticklabels(model_metrics.keys())\n",
        "ax.legend()\n",
        "\n",
        "# Set the lower limit for the y-axis to the smallest score minus a small margin\n",
        "ax.set_ylim([min_score - 0.05, 1])\n",
        "\n",
        "# Show the plot\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:08:53.525033Z",
          "iopub.execute_input": "2024-03-19T10:08:53.526259Z",
          "iopub.status.idle": "2024-03-19T10:08:53.599815Z",
          "shell.execute_reply.started": "2024-03-19T10:08:53.526218Z",
          "shell.execute_reply": "2024-03-19T10:08:53.598252Z"
        },
        "trusted": true,
        "id": "mNepS4yr_ikd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-18T19:35:12.168667Z",
          "iopub.execute_input": "2024-03-18T19:35:12.169511Z",
          "iopub.status.idle": "2024-03-18T19:35:12.180543Z",
          "shell.execute_reply.started": "2024-03-18T19:35:12.169456Z",
          "shell.execute_reply": "2024-03-18T19:35:12.179364Z"
        },
        "trusted": true,
        "id": "cbPo1FM0_ike"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grouped_data = diabete.groupby('Glucose')\n",
        "\n",
        "# Display the first few rows of each group\n",
        "for name, group in grouped_data:\n",
        "    print(f\"Group: {name}\")\n",
        "    print(group)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T10:09:04.05074Z",
          "iopub.execute_input": "2024-03-19T10:09:04.051132Z",
          "iopub.status.idle": "2024-03-19T10:09:04.096024Z",
          "shell.execute_reply.started": "2024-03-19T10:09:04.051102Z",
          "shell.execute_reply": "2024-03-19T10:09:04.094638Z"
        },
        "trusted": true,
        "id": "lZvYuBYk_ike"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that the correct dataset file has been uploaded, let's proceed with the data cleaning steps\n",
        "\n",
        "# Re-loading the dataset from the newly uploaded file\n",
        "\n",
        "\n",
        "# 1. Checking for Missing Values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# 2. Checking Data Types\n",
        "data_types = df.dtypes\n",
        "\n",
        "# 3. Outlier Detection (Using a simple method like IQR for demonstration)\n",
        "# Here, just calculating IQR for each column but not removing outliers\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum()\n",
        "\n",
        "# 4. Checking for Duplicate Rows\n",
        "duplicate_rows = df.duplicated().sum()\n",
        "\n",
        "missing_values, data_types, outliers, duplicate_rows\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T13:56:45.215436Z",
          "iopub.execute_input": "2024-03-19T13:56:45.215876Z",
          "iopub.status.idle": "2024-03-19T13:56:45.242733Z",
          "shell.execute_reply.started": "2024-03-19T13:56:45.215842Z",
          "shell.execute_reply": "2024-03-19T13:56:45.24159Z"
        },
        "trusted": true,
        "id": "IB-WqqlX_ike"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(df.columns[:-1]): # Exclude 'Outcome' column\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    sns.boxplot(y=df[col])\n",
        "    plt.title(col)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:02:22.056133Z",
          "iopub.execute_input": "2024-03-19T14:02:22.05657Z",
          "iopub.status.idle": "2024-03-19T14:02:23.671945Z",
          "shell.execute_reply.started": "2024-03-19T14:02:22.056539Z",
          "shell.execute_reply": "2024-03-19T14:02:23.670881Z"
        },
        "trusted": true,
        "id": "KKm5Cc9a_ike"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Calculating IQR for each column\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Identifying rows with outliers\n",
        "outlier_indices = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)\n",
        "outlier_rows = df[outlier_indices]\n",
        "\n",
        "print(outlier_rows)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:04:58.110548Z",
          "iopub.execute_input": "2024-03-19T14:04:58.111028Z",
          "iopub.status.idle": "2024-03-19T14:04:58.133785Z",
          "shell.execute_reply.started": "2024-03-19T14:04:58.110994Z",
          "shell.execute_reply": "2024-03-19T14:04:58.13252Z"
        },
        "trusted": true,
        "id": "lZ8i5eqY_ikf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Calculating IQR for 'BMI' and 'SkinThickness'\n",
        "Q1_BMI = df['BMI'].quantile(0.25)\n",
        "Q3_BMI = df['BMI'].quantile(0.75)\n",
        "IQR_BMI = Q3_BMI - Q1_BMI\n",
        "\n",
        "Q1_SkinThickness = df['SkinThickness'].quantile(0.25)\n",
        "Q3_SkinThickness = df['SkinThickness'].quantile(0.75)\n",
        "IQR_SkinThickness = Q3_SkinThickness - Q1_SkinThickness\n",
        "\n",
        "# Identifying rows with outliers in 'BMI' or 'SkinThickness'\n",
        "outliers_BMI = (df['BMI'] < (Q1_BMI - 1.5 * IQR_BMI)) | (df['BMI'] > (Q3_BMI + 1.5 * IQR_BMI))\n",
        "outliers_SkinThickness = (df['SkinThickness'] < (Q1_SkinThickness - 1.5 * IQR_SkinThickness)) | (df['SkinThickness'] > (Q3_SkinThickness + 1.5 * IQR_SkinThickness))\n",
        "\n",
        "# Filtering rows\n",
        "outlier_rows_bmi_skin = df[outliers_BMI | outliers_SkinThickness]\n",
        "\n",
        "print(outlier_rows_bmi_skin)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:07:28.262521Z",
          "iopub.execute_input": "2024-03-19T14:07:28.263095Z",
          "iopub.status.idle": "2024-03-19T14:07:28.289984Z",
          "shell.execute_reply.started": "2024-03-19T14:07:28.263041Z",
          "shell.execute_reply": "2024-03-19T14:07:28.288365Z"
        },
        "trusted": true,
        "id": "5G6B4XFc_ikf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Excluding 'Outcome' and 'Pregnancies' from the columns to check\n",
        "columns_to_check = df.columns[~df.columns.isin(['Outcome', 'Pregnancies'])]\n",
        "\n",
        "# Checking for zeros in the selected columns\n",
        "rows_with_zeros = df[columns_to_check].eq(0).any(axis=1)\n",
        "\n",
        "# Filtering rows that have at least one zero value in the selected columns\n",
        "rows_with_at_least_one_zero_corrected = df[rows_with_zeros]\n",
        "\n",
        "print(rows_with_at_least_one_zero_corrected)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:14:15.364637Z",
          "iopub.execute_input": "2024-03-19T14:14:15.365073Z",
          "iopub.status.idle": "2024-03-19T14:14:15.378372Z",
          "shell.execute_reply.started": "2024-03-19T14:14:15.365043Z",
          "shell.execute_reply": "2024-03-19T14:14:15.377242Z"
        },
        "trusted": true,
        "id": "8ZfYVDo5_ikf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Dropping the 'Insulin' and 'SkinThickness' columns\n",
        "df_dropped = df.drop(columns=['Insulin', 'SkinThickness'])\n",
        "\n",
        "print(df_dropped)\n",
        "#now i have two dfs to perform my test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:39:37.802625Z",
          "iopub.execute_input": "2024-03-19T14:39:37.803081Z",
          "iopub.status.idle": "2024-03-19T14:39:37.815275Z",
          "shell.execute_reply.started": "2024-03-19T14:39:37.803049Z",
          "shell.execute_reply": "2024-03-19T14:39:37.813861Z"
        },
        "trusted": true,
        "id": "YwJYpdy4_ikf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df_dropped' is your DataFrame with 'Insulin' and 'SkinThickness' dropped\n",
        "\n",
        "# Recalculating IQR for the modified dataset\n",
        "Q1 = df_dropped.quantile(0.25)\n",
        "Q3 = df_dropped.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Capping the outliers\n",
        "df_capped = df_dropped.clip(Q1 - 1.5 * IQR, Q3 + 1.5 * IQR, axis=1)\n",
        "\n",
        "print(df_capped.head())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:39:42.757577Z",
          "iopub.execute_input": "2024-03-19T14:39:42.758002Z",
          "iopub.status.idle": "2024-03-19T14:39:42.783148Z",
          "shell.execute_reply.started": "2024-03-19T14:39:42.757972Z",
          "shell.execute_reply": "2024-03-19T14:39:42.781922Z"
        },
        "trusted": true,
        "id": "DICORM6K_ikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(df_capped.columns[:-1]): # Exclude 'Outcome' column\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    sns.boxplot(y=df_capped[col])\n",
        "    plt.title(col)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:40:02.577376Z",
          "iopub.execute_input": "2024-03-19T14:40:02.577827Z",
          "iopub.status.idle": "2024-03-19T14:40:03.786735Z",
          "shell.execute_reply.started": "2024-03-19T14:40:02.577793Z",
          "shell.execute_reply": "2024-03-19T14:40:03.785639Z"
        },
        "trusted": true,
        "id": "rhOCq5DQ_ikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Assuming 'df_dropped' is your DataFrame without 'Insulin' and 'SkinThickness'\n",
        "\n",
        "# Normalizing the features\n",
        "df_normalized = (df_capped - df_capped.mean()) / df_capped.std()\n",
        "\n",
        "# Plotting histograms with normal distribution fits for each feature\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(df_normalized.columns):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    sns.histplot(df_normalized[col], kde=True, stat=\"density\", linewidth=0)\n",
        "    plt.plot(np.linspace(-3, 3, 100), norm.pdf(np.linspace(-3, 3, 100)), color='red')  # Normal distribution\n",
        "    plt.title(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:43:52.163239Z",
          "iopub.execute_input": "2024-03-19T14:43:52.163714Z",
          "iopub.status.idle": "2024-03-19T14:43:54.508489Z",
          "shell.execute_reply.started": "2024-03-19T14:43:52.163677Z",
          "shell.execute_reply": "2024-03-19T14:43:54.507149Z"
        },
        "trusted": true,
        "id": "a3vbM_Bo_ikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Selecting relevant columns\n",
        "columns_to_consider = df.columns[(df.columns != 'Pregnancies') & (df.columns != 'Outcome')]\n",
        "\n",
        "# Calculating the percentage of zeros in each of these columns\n",
        "percent_zeros = (df[columns_to_consider] == 0).sum() / len(df) * 100\n",
        "\n",
        "print(percent_zeros)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:18:32.532196Z",
          "iopub.execute_input": "2024-03-19T14:18:32.532734Z",
          "iopub.status.idle": "2024-03-19T14:18:32.544906Z",
          "shell.execute_reply.started": "2024-03-19T14:18:32.532678Z",
          "shell.execute_reply": "2024-03-19T14:18:32.54311Z"
        },
        "trusted": true,
        "id": "rcfn2Q0D_ikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T14:11:30.494091Z",
          "iopub.execute_input": "2024-03-19T14:11:30.49448Z",
          "iopub.status.idle": "2024-03-19T14:11:30.514926Z",
          "shell.execute_reply.started": "2024-03-19T14:11:30.494452Z",
          "shell.execute_reply": "2024-03-19T14:11:30.51357Z"
        },
        "trusted": true,
        "id": "B8GwyvFm_ikh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame after cleaning\n",
        "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for each column\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Determine outliers using IQR\n",
        "# Any value that is beyond Q1 - 1.5 * IQR or Q3 + 1.5 * IQR is considered an outlier\n",
        "outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))\n",
        "\n",
        "# You can choose to remove outliers or cap them\n",
        "# For example, to remove outliers:\n",
        "#df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "# Define a cap value for each column, for example, the 95th percentile\n",
        "cap_value = df.quantile(0.95)\n",
        "\n",
        "# Cap values above the 95th percentile\n",
        "for column in df.columns:\n",
        "    df[column] = df[column].mask(df[column] > cap_value[column], cap_value[column])\n",
        "\n",
        "# Similarly, you can define a floor value, for example, the 5th percentile\n",
        "floor_value = df.quantile(0.05)\n",
        "\n",
        "# Floor values below the 5th percentile\n",
        "for column in df.columns:\n",
        "    df[column] = df[column].mask(df[column] < floor_value[column], floor_value[column])\n",
        "\n",
        "# Plotting box plots to visualize outliers\n",
        "plt.figure(figsize=(12, 6))\n",
        "df.boxplot()\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Box plot for each column in the dataset')\n",
        "plt.show()\n",
        "#now i have capped data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:13:04.680395Z",
          "iopub.execute_input": "2024-03-17T18:13:04.680894Z",
          "iopub.status.idle": "2024-03-17T18:13:05.121146Z",
          "shell.execute_reply.started": "2024-03-17T18:13:04.680855Z",
          "shell.execute_reply": "2024-03-17T18:13:05.119943Z"
        },
        "trusted": true,
        "id": "C6jBmTcY_ikh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types\n",
        "print(df.dtypes)\n",
        "\n",
        "# Convert data types if needed\n",
        "# For example, converting a column to categorical\n",
        "#df['column_name'] = df['column_name'].astype('category')\n",
        "\n",
        "# Or converting a column to a numerical data type\n",
        "#df['column_name'] = pd.to_numeric(df['column_name'], errors='coerce')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T18:36:00.378293Z",
          "iopub.execute_input": "2024-03-16T18:36:00.379165Z",
          "iopub.status.idle": "2024-03-16T18:36:00.386967Z",
          "shell.execute_reply.started": "2024-03-16T18:36:00.379125Z",
          "shell.execute_reply": "2024-03-16T18:36:00.385695Z"
        },
        "trusted": true,
        "id": "I9SIlRJi_ikh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#have a overview of my data\n",
        "df.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T18:38:58.873007Z",
          "iopub.execute_input": "2024-03-16T18:38:58.873396Z",
          "iopub.status.idle": "2024-03-16T18:38:58.910049Z",
          "shell.execute_reply.started": "2024-03-16T18:38:58.873366Z",
          "shell.execute_reply": "2024-03-16T18:38:58.908917Z"
        },
        "trusted": true,
        "id": "ft5OtIO3_ikh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Descriptive statistics for all numerical columns\n",
        "descriptive_stats = df.describe()\n",
        "\n",
        "# Print the descriptive statistics\n",
        "print(descriptive_stats)\n",
        "\n",
        "# Additionally, you can calculate skewness and kurtosis for each column\n",
        "skewness = df.skew()\n",
        "kurtosis = df.kurtosis()\n",
        "\n",
        "# Print skewness and kurtosis\n",
        "print(\"Skewness:\\n\", skewness)\n",
        "print(\"Kurtosis:\\n\", kurtosis)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T18:40:29.795839Z",
          "iopub.execute_input": "2024-03-16T18:40:29.79638Z",
          "iopub.status.idle": "2024-03-16T18:40:29.837048Z",
          "shell.execute_reply.started": "2024-03-16T18:40:29.796335Z",
          "shell.execute_reply": "2024-03-16T18:40:29.835888Z"
        },
        "trusted": true,
        "id": "_Srn3VIe_ikh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency distribution for categorical columns\n",
        "for column in df.select_dtypes(include=['category']).columns:\n",
        "    print(df[column].value_counts())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T18:42:04.435558Z",
          "iopub.execute_input": "2024-03-16T18:42:04.43599Z",
          "iopub.status.idle": "2024-03-16T18:42:04.443693Z",
          "shell.execute_reply.started": "2024-03-16T18:42:04.435956Z",
          "shell.execute_reply": "2024-03-16T18:42:04.442058Z"
        },
        "trusted": true,
        "id": "u4AjMWXN_iki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "#you can correct bins\n",
        "\n",
        "# Histograms for all numerical columns\n",
        "df.hist(bins=16, figsize=(15, 11), layout=(4, 4))\n",
        "plt.suptitle('Histograms of the Numerical Columns')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T19:09:11.556305Z",
          "iopub.execute_input": "2024-03-16T19:09:11.556696Z",
          "iopub.status.idle": "2024-03-16T19:09:14.20401Z",
          "shell.execute_reply.started": "2024-03-16T19:09:11.556668Z",
          "shell.execute_reply": "2024-03-16T19:09:14.202951Z"
        },
        "trusted": true,
        "id": "5vcN9ZdV_iki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "df.boxplot()\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Box Plots of the Numerical Columns')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T18:48:41.521972Z",
          "iopub.execute_input": "2024-03-16T18:48:41.522415Z",
          "iopub.status.idle": "2024-03-16T18:48:41.924842Z",
          "shell.execute_reply.started": "2024-03-16T18:48:41.522381Z",
          "shell.execute_reply": "2024-03-16T18:48:41.923868Z"
        },
        "trusted": true,
        "id": "lgOmiUF-_ikn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df)\n",
        "#change colours later\n",
        "plt.suptitle('Pairplot of the Numerical Columns')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T18:51:49.648665Z",
          "iopub.execute_input": "2024-03-16T18:51:49.649091Z",
          "iopub.status.idle": "2024-03-16T18:52:14.638996Z",
          "shell.execute_reply.started": "2024-03-16T18:51:49.649058Z",
          "shell.execute_reply": "2024-03-16T18:52:14.638014Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "JbpziI4x_ikn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title('Heatmap of the Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T18:54:04.042005Z",
          "iopub.execute_input": "2024-03-16T18:54:04.042357Z",
          "iopub.status.idle": "2024-03-16T18:54:04.719942Z",
          "shell.execute_reply.started": "2024-03-16T18:54:04.04233Z",
          "shell.execute_reply": "2024-03-16T18:54:04.718664Z"
        },
        "trusted": true,
        "id": "0Zfa5KeR_iko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Apply log transformation\n",
        "df['Age_Transformed'] = np.log(df['Age'] + 1)  # Adding 1 to avoid log(0)\n",
        "\n",
        "# Plot the histogram of the log-transformed data\n",
        "plt.hist(df['Age_Transformed'], bins=15)\n",
        "plt.title('Histogram of Log-Transformed Data')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T19:10:01.838331Z",
          "iopub.execute_input": "2024-03-16T19:10:01.838765Z",
          "iopub.status.idle": "2024-03-16T19:10:02.199783Z",
          "shell.execute_reply.started": "2024-03-16T19:10:01.838728Z",
          "shell.execute_reply": "2024-03-16T19:10:02.19849Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "cQ4fVphN_iko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T19:10:06.156789Z",
          "iopub.execute_input": "2024-03-16T19:10:06.157449Z",
          "iopub.status.idle": "2024-03-16T19:10:06.177291Z",
          "shell.execute_reply.started": "2024-03-16T19:10:06.157415Z",
          "shell.execute_reply": "2024-03-16T19:10:06.175852Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "IrtzR1be_ikp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Apply log transformation\n",
        "df['log_transformed_column'] = np.log(df['column'] + 1)  # Adding 1 to avoid log(0)\n",
        "\n",
        "# Plot the histogram of the log-transformed data\n",
        "plt.hist(df['log_transformed_column'], bins=15)\n",
        "plt.title('Histogram of Log-Transformed Data')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mYfNaJBZ_ikp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'df' is your DataFrame and 'var1' and 'var2' are the two strong related variables\n",
        "sns.lmplot(x='Age', y='Glucose', data=df, aspect=1.5)\n",
        "plt.title('Scatter Plot with Regression Line')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T19:23:45.813718Z",
          "iopub.execute_input": "2024-03-16T19:23:45.814106Z",
          "iopub.status.idle": "2024-03-16T19:23:46.681382Z",
          "shell.execute_reply.started": "2024-03-16T19:23:45.814075Z",
          "shell.execute_reply": "2024-03-16T19:23:46.680335Z"
        },
        "trusted": true,
        "id": "0CiAYqvE_ikp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'df' is your DataFrame and 'var1' and 'var2' are the two strong related variables\n",
        "sns.lmplot(x='Glucose', y='Age', data=df, aspect=1.5)\n",
        "plt.title('Scatter Plot with Regression Line')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T19:24:19.239784Z",
          "iopub.execute_input": "2024-03-16T19:24:19.240502Z",
          "iopub.status.idle": "2024-03-16T19:24:20.039279Z",
          "shell.execute_reply.started": "2024-03-16T19:24:19.240467Z",
          "shell.execute_reply": "2024-03-16T19:24:20.037986Z"
        },
        "trusted": true,
        "id": "_M2kDZ-R_ikq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'df' is your DataFrame and 'var1' and 'var2' are the two strong related variables\n",
        "sns.lmplot(x='SkinThickness', y='Insulin', data=df, aspect=1.5)\n",
        "plt.title('Scatter Plot with Regression Line')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T19:25:17.729591Z",
          "iopub.execute_input": "2024-03-16T19:25:17.730058Z",
          "iopub.status.idle": "2024-03-16T19:25:18.491841Z",
          "shell.execute_reply.started": "2024-03-16T19:25:17.730026Z",
          "shell.execute_reply": "2024-03-16T19:25:18.490666Z"
        },
        "trusted": true,
        "id": "60b5RW2b_ikq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Residual Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.residplot(x='Age', y='Glucose', data=df, lowess=True)\n",
        "plt.title('Residual Plot')\n",
        "plt.xlabel('Independent Variable (var1)')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()\n",
        "\n",
        "# Density Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(df['Glucose'], df['Age'])\n",
        "plt.title('Density Plot')\n",
        "plt.xlabel('Independent Variable (var1)')\n",
        "plt.ylabel('Dependent Variable (var2)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T19:28:28.915099Z",
          "iopub.execute_input": "2024-03-16T19:28:28.916343Z",
          "iopub.status.idle": "2024-03-16T19:28:29.374159Z",
          "shell.execute_reply.started": "2024-03-16T19:28:28.91629Z",
          "shell.execute_reply": "2024-03-16T19:28:29.372797Z"
        },
        "trusted": true,
        "id": "44-vqIvo_ikq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Density Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(x=df['Age'], y=df['Glucose'], cmap=\"Reds\", shade=True)\n",
        "plt.title('Density Plot')\n",
        "plt.xlabel('Independent Variable (Age)')\n",
        "plt.ylabel('Dependent Variable (Glucose)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T19:30:21.97766Z",
          "iopub.execute_input": "2024-03-16T19:30:21.978133Z",
          "iopub.status.idle": "2024-03-16T19:30:22.926554Z",
          "shell.execute_reply.started": "2024-03-16T19:30:21.978098Z",
          "shell.execute_reply": "2024-03-16T19:30:22.925365Z"
        },
        "trusted": true,
        "id": "437M_m-w_ikq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lmplot(x='Outcome', y='Glucose', data=df, aspect=1.5)\n",
        "plt.title('Scatter Plot with Regression Line')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:10:44.139071Z",
          "iopub.execute_input": "2024-03-17T18:10:44.139516Z",
          "iopub.status.idle": "2024-03-17T18:10:44.846549Z",
          "shell.execute_reply.started": "2024-03-17T18:10:44.139483Z",
          "shell.execute_reply": "2024-03-17T18:10:44.845151Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "GEhb9VdF_ikr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a boxplot to show the relevance of 'Outcome' to 'Glucose'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Outcome', y='BMI', data=df)\n",
        "plt.title('Boxplot of Glucose Levels by Outcome')\n",
        "plt.xlabel('Outcome (0: Non-diabetic, 1: Diabetic)')\n",
        "plt.ylabel('BMI')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:15:12.318792Z",
          "iopub.execute_input": "2024-03-17T18:15:12.320386Z",
          "iopub.status.idle": "2024-03-17T18:15:12.582195Z",
          "shell.execute_reply.started": "2024-03-17T18:15:12.320337Z",
          "shell.execute_reply": "2024-03-17T18:15:12.58104Z"
        },
        "trusted": true,
        "id": "QmKUrgjA_ikr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'df' is your DataFrame and 'var1' and 'var2' are the two strong related variables\n",
        "sns.lmplot(x='Outcome', y='BMI', data=df, aspect=1.5)\n",
        "plt.title('Scatter Plot with Regression Line')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:17:00.550406Z",
          "iopub.execute_input": "2024-03-17T18:17:00.55094Z",
          "iopub.status.idle": "2024-03-17T18:17:01.132462Z",
          "shell.execute_reply.started": "2024-03-17T18:17:00.550895Z",
          "shell.execute_reply": "2024-03-17T18:17:01.13126Z"
        },
        "trusted": true,
        "id": "mMa7Z0WG_ikr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Residual Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.residplot(x='Outcome', y='BMI', data=df, lowess=True)\n",
        "plt.title('Residual Plot')\n",
        "plt.xlabel('Independent Variable (Outcome)')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()\n",
        "\n",
        "# Density Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(df['Outcome'], df['BMI'])\n",
        "plt.title('Density Plot')\n",
        "plt.xlabel('Independent Variable (Outcome)')\n",
        "plt.ylabel('Dependent Variable (BMI)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:24:05.583202Z",
          "iopub.execute_input": "2024-03-17T18:24:05.583674Z",
          "iopub.status.idle": "2024-03-17T18:24:05.938964Z",
          "shell.execute_reply.started": "2024-03-17T18:24:05.583636Z",
          "shell.execute_reply": "2024-03-17T18:24:05.937353Z"
        },
        "trusted": true,
        "id": "FBDWWwnr_ikr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Residual Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.residplot(x='SkinThickness', y='Insulin', data=df, lowess=True)\n",
        "plt.title('Residual Plot')\n",
        "plt.xlabel('Independent Variable (SckinThickness)')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()\n",
        "\n",
        "# Density Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(df['SkinThickness'], df['Insulin'])\n",
        "plt.title('Density Plot')\n",
        "plt.xlabel('Independent Variable (SkinThickness)')\n",
        "plt.ylabel('Dependent Variable (Insulin)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:25:02.783998Z",
          "iopub.execute_input": "2024-03-17T18:25:02.78499Z",
          "iopub.status.idle": "2024-03-17T18:25:03.202726Z",
          "shell.execute_reply.started": "2024-03-17T18:25:02.784919Z",
          "shell.execute_reply": "2024-03-17T18:25:03.200964Z"
        },
        "trusted": true,
        "id": "Vt1Qk6Nl_iks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Density Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(x=df['Outcome'], y=df['BMI'], cmap=\"Reds\", shade=True)\n",
        "plt.title('Density Plot')\n",
        "plt.xlabel('Independent Variable (Outcome)')\n",
        "plt.ylabel('Dependent Variable (BMI)')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:22:18.511832Z",
          "iopub.execute_input": "2024-03-17T18:22:18.512311Z",
          "iopub.status.idle": "2024-03-17T18:22:19.374408Z",
          "shell.execute_reply.started": "2024-03-17T18:22:18.512274Z",
          "shell.execute_reply": "2024-03-17T18:22:19.3732Z"
        },
        "trusted": true,
        "id": "lwEIl7Kj_iks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Interaction Terms\n",
        "df['Glucose_Insulin'] = df['Glucose'] * df['Insulin']\n",
        "\n",
        "# Polynomial Features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "poly_features = poly.fit_transform(df[['Glucose', 'BloodPressure']])\n",
        "df_poly_glucose_bloodpressure = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(input_features=['Glucose', 'BloodPressure']))\n",
        "\n",
        "# Binning\n",
        "df['Age_Group'] = pd.cut(df['Age'], bins=[20, 30, 40, 50, 60, 70, 80], labels=['20s', '30s', '40s', '50s', '60s', '70+'])\n",
        "\n",
        "# Normalization/Standardization\n",
        "scaler = StandardScaler()\n",
        "df[['Glucose', 'BloodPressure']] = scaler.fit_transform(df[['Glucose', 'BloodPressure']])\n",
        "\n",
        "# Encoding Categorical Variables\n",
        "# Assuming 'Outcome' is the only categorical variable in the DataFrame\n",
        "encoder = OneHotEncoder()\n",
        "encoded_features = encoder.fit_transform(df[['Outcome']]).toarray()\n",
        "df_encoded = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['Outcome']))\n",
        "\n",
        "# Combine all features into one DataFrame\n",
        "df_final = pd.concat([df, df_poly, df_encoded], axis=1)\n",
        "print('Step Feature Engineering done')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:59:12.451305Z",
          "iopub.execute_input": "2024-03-17T18:59:12.45174Z",
          "iopub.status.idle": "2024-03-17T18:59:12.479623Z",
          "shell.execute_reply.started": "2024-03-17T18:59:12.451708Z",
          "shell.execute_reply": "2024-03-17T18:59:12.478581Z"
        },
        "trusted": true,
        "id": "eBHeMLv3_iks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:38:43.048775Z",
          "iopub.execute_input": "2024-03-17T18:38:43.049411Z",
          "iopub.status.idle": "2024-03-17T18:38:43.082265Z",
          "shell.execute_reply.started": "2024-03-17T18:38:43.049362Z",
          "shell.execute_reply": "2024-03-17T18:38:43.08102Z"
        },
        "trusted": true,
        "id": "mNrDO1Am_iks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_poly"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:43:31.12527Z",
          "iopub.execute_input": "2024-03-17T18:43:31.125783Z",
          "iopub.status.idle": "2024-03-17T18:43:31.14378Z",
          "shell.execute_reply.started": "2024-03-17T18:43:31.125751Z",
          "shell.execute_reply": "2024-03-17T18:43:31.142442Z"
        },
        "trusted": true,
        "id": "gxsCP1uK_ikt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polynomial Features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "poly_features = poly.fit_transform(df[['Outcome', 'BMI']])\n",
        "df_poly_2 = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(input_features=['Outcome', 'BMI']))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:45:06.238207Z",
          "iopub.execute_input": "2024-03-17T18:45:06.238643Z",
          "iopub.status.idle": "2024-03-17T18:45:06.249763Z",
          "shell.execute_reply.started": "2024-03-17T18:45:06.238612Z",
          "shell.execute_reply": "2024-03-17T18:45:06.24876Z"
        },
        "trusted": true,
        "id": "eOpFjmbr_ikt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_poly_2.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:47:59.232344Z",
          "iopub.execute_input": "2024-03-17T18:47:59.232842Z",
          "iopub.status.idle": "2024-03-17T18:47:59.261566Z",
          "shell.execute_reply.started": "2024-03-17T18:47:59.232802Z",
          "shell.execute_reply": "2024-03-17T18:47:59.260665Z"
        },
        "trusted": true,
        "id": "_hArOXOq_ikt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_matrix = df_poly_features_insulin_skinthickness.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
        "plt.title('Heatmap of Feature Correlation Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:57:08.199667Z",
          "iopub.execute_input": "2024-03-17T18:57:08.200196Z",
          "iopub.status.idle": "2024-03-17T18:57:08.61479Z",
          "shell.execute_reply.started": "2024-03-17T18:57:08.200157Z",
          "shell.execute_reply": "2024-03-17T18:57:08.613473Z"
        },
        "trusted": true,
        "id": "Acavn58r_ikt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "poly_features_insulin_skinthickness = poly.fit_transform(df[['Insulin', 'SkinThickness']])\n",
        "df_poly_features_insulin_skinthickness = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(input_features=['Insulin', 'SkinThickness']))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:56:27.348533Z",
          "iopub.execute_input": "2024-03-17T18:56:27.34905Z",
          "iopub.status.idle": "2024-03-17T18:56:27.3625Z",
          "shell.execute_reply.started": "2024-03-17T18:56:27.349Z",
          "shell.execute_reply": "2024-03-17T18:56:27.360702Z"
        },
        "trusted": true,
        "id": "GPpny0jz_iku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_poly_features_insulin_skinthickness"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:56:48.290862Z",
          "iopub.execute_input": "2024-03-17T18:56:48.291409Z",
          "iopub.status.idle": "2024-03-17T18:56:48.314873Z",
          "shell.execute_reply.started": "2024-03-17T18:56:48.291367Z",
          "shell.execute_reply": "2024-03-17T18:56:48.313479Z"
        },
        "trusted": true,
        "id": "tBiVd1D0_iku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "poly_features_insulin_skinthickness = poly.fit_transform(df[['Age', 'SkinThickness']])\n",
        "df_poly_features_Age_skinthickness = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(input_features=['Age', 'SkinThickness']))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:57:57.044233Z",
          "iopub.execute_input": "2024-03-17T18:57:57.044705Z",
          "iopub.status.idle": "2024-03-17T18:57:57.056822Z",
          "shell.execute_reply.started": "2024-03-17T18:57:57.044672Z",
          "shell.execute_reply": "2024-03-17T18:57:57.055549Z"
        },
        "trusted": true,
        "id": "553p1NEB_iku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_matrix = df_poly_features_Age_skinthickness.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
        "plt.title('Heatmap of Feature Correlation Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:58:16.559251Z",
          "iopub.execute_input": "2024-03-17T18:58:16.559713Z",
          "iopub.status.idle": "2024-03-17T18:58:16.961663Z",
          "shell.execute_reply.started": "2024-03-17T18:58:16.559673Z",
          "shell.execute_reply": "2024-03-17T18:58:16.960443Z"
        },
        "trusted": true,
        "id": "YjIaTk5J_iku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_matrix = df_poly_glucose_bloodpressure.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
        "plt.title('Heatmap of Feature Correlation Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T18:59:24.329886Z",
          "iopub.execute_input": "2024-03-17T18:59:24.330399Z",
          "iopub.status.idle": "2024-03-17T18:59:24.740121Z",
          "shell.execute_reply.started": "2024-03-17T18:59:24.330361Z",
          "shell.execute_reply": "2024-03-17T18:59:24.738829Z"
        },
        "trusted": true,
        "id": "fFmYFAp3_iku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T19:02:43.29927Z",
          "iopub.execute_input": "2024-03-17T19:02:43.299798Z",
          "iopub.status.idle": "2024-03-17T19:02:43.323283Z",
          "shell.execute_reply.started": "2024-03-17T19:02:43.299765Z",
          "shell.execute_reply": "2024-03-17T19:02:43.321916Z"
        },
        "trusted": true,
        "id": "tPWn-npY_ikv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your main DataFrame and 'df_encoded' is the DataFrame with encoded features\n",
        "\n",
        "# Concatenate the encoded features to the main DataFrame\n",
        "df = pd.concat([df, df_encoded], axis=1)\n",
        "\n",
        "# Optionally, you can drop the original 'Outcome' column if it's no longer needed\n",
        "df.drop('Outcome', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T19:04:12.111188Z",
          "iopub.execute_input": "2024-03-17T19:04:12.111708Z",
          "iopub.status.idle": "2024-03-17T19:04:12.121895Z",
          "shell.execute_reply.started": "2024-03-17T19:04:12.111672Z",
          "shell.execute_reply": "2024-03-17T19:04:12.12059Z"
        },
        "trusted": true,
        "id": "bHuAEIZL_ikv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T19:04:17.960891Z",
          "iopub.execute_input": "2024-03-17T19:04:17.961433Z",
          "iopub.status.idle": "2024-03-17T19:04:17.990522Z",
          "shell.execute_reply.started": "2024-03-17T19:04:17.961393Z",
          "shell.execute_reply": "2024-03-17T19:04:17.98956Z"
        },
        "trusted": true,
        "id": "KUkFXmQN_ikv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Age_SkinThickness'] = df['Age'] * df['SkinThickness']\n",
        "df['Insulin_SkinThickness'] = df['Insulin'] * df['SkinThickness']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T19:06:39.783205Z",
          "iopub.execute_input": "2024-03-17T19:06:39.783683Z",
          "iopub.status.idle": "2024-03-17T19:06:39.791963Z",
          "shell.execute_reply.started": "2024-03-17T19:06:39.783651Z",
          "shell.execute_reply": "2024-03-17T19:06:39.790809Z"
        },
        "trusted": true,
        "id": "ykav-CX6_ikv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T19:06:41.460889Z",
          "iopub.execute_input": "2024-03-17T19:06:41.461392Z",
          "iopub.status.idle": "2024-03-17T19:06:41.488286Z",
          "shell.execute_reply.started": "2024-03-17T19:06:41.461353Z",
          "shell.execute_reply": "2024-03-17T19:06:41.486802Z"
        },
        "trusted": true,
        "id": "CfaDAhEl_ikw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'Outcome' is the target variable\n",
        "df_droped_age=df.drop(['Age_Group' , 'Outcome_1'] , axis=1)\n",
        "# Prepare the features and target\n",
        "X = df_droped_age.drop('Outcome_0', axis=1)  # Features\n",
        "y = df_droped_age['Outcome_0']  # Target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "#logreg = LogisticRegression()\n",
        "\n",
        "# Fit the model on the training data\n",
        "#logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "#y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "#accuracy = accuracy_score(y_test, y_pred)\n",
        "#print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:18:56.565335Z",
          "iopub.execute_input": "2024-03-17T20:18:56.566553Z",
          "iopub.status.idle": "2024-03-17T20:18:56.578272Z",
          "shell.execute_reply.started": "2024-03-17T20:18:56.56651Z",
          "shell.execute_reply": "2024-03-17T20:18:56.577425Z"
        },
        "trusted": true,
        "id": "zLJgZ7S7_ikw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'y_test' contains the true values and 'y_pred' contains the predictions from your model\n",
        "\n",
        "# Calculate R-squared\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(f'R-squared: {r_squared:.2f}')\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:00:46.889272Z",
          "iopub.execute_input": "2024-03-17T20:00:46.890363Z",
          "iopub.status.idle": "2024-03-17T20:00:46.900474Z",
          "shell.execute_reply.started": "2024-03-17T20:00:46.890311Z",
          "shell.execute_reply": "2024-03-17T20:00:46.899228Z"
        },
        "trusted": true,
        "id": "18nzYHYY_ikw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T19:50:23.470752Z",
          "iopub.execute_input": "2024-03-17T19:50:23.471325Z",
          "iopub.status.idle": "2024-03-17T19:50:23.48235Z",
          "shell.execute_reply.started": "2024-03-17T19:50:23.471287Z",
          "shell.execute_reply": "2024-03-17T19:50:23.481079Z"
        },
        "trusted": true,
        "id": "33umjhGI_ikw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Assuming 'X_train' and 'y_train' are your training data\n",
        "\n",
        "# Initialize the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# View the coefficients\n",
        "print(f'Coefficients: {model.coef_}')\n",
        "# View the intercept\n",
        "print(f'Intercept: {model.intercept_}')\n",
        "\n",
        "# If you have test data 'X_test' and 'y_test', you can make predictions and view performance metrics\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(f'Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred)}')\n",
        "print(f'Coefficient of Determination (R^2): {r2_score(y_test, y_pred)}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T19:51:29.949412Z",
          "iopub.execute_input": "2024-03-17T19:51:29.950803Z",
          "iopub.status.idle": "2024-03-17T19:51:29.977632Z",
          "shell.execute_reply.started": "2024-03-17T19:51:29.950749Z",
          "shell.execute_reply": "2024-03-17T19:51:29.976772Z"
        },
        "trusted": true,
        "id": "6XAzsUSf_ikw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T19:52:46.240541Z",
          "iopub.execute_input": "2024-03-17T19:52:46.241484Z",
          "iopub.status.idle": "2024-03-17T19:52:46.251234Z",
          "shell.execute_reply.started": "2024-03-17T19:52:46.241443Z",
          "shell.execute_reply": "2024-03-17T19:52:46.250215Z"
        },
        "trusted": true,
        "id": "ft7a02je_ikx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T19:53:28.630788Z",
          "iopub.execute_input": "2024-03-17T19:53:28.63126Z",
          "iopub.status.idle": "2024-03-17T19:53:28.639062Z",
          "shell.execute_reply.started": "2024-03-17T19:53:28.631229Z",
          "shell.execute_reply": "2024-03-17T19:53:28.637894Z"
        },
        "trusted": true,
        "id": "HDOByTP6_ikx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f'Random Forest Model Accuracy: {accuracy_rf:.2f}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:12:09.208699Z",
          "iopub.execute_input": "2024-03-17T20:12:09.209202Z",
          "iopub.status.idle": "2024-03-17T20:12:09.478274Z",
          "shell.execute_reply.started": "2024-03-17T20:12:09.209154Z",
          "shell.execute_reply": "2024-03-17T20:12:09.477032Z"
        },
        "trusted": true,
        "id": "yEMdUe2-_iky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize the Gradient Boosting model\n",
        "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "print(f'Gradient Boosting Model Accuracy: {accuracy_gb:.2f}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:19:21.297875Z",
          "iopub.execute_input": "2024-03-17T20:19:21.29842Z",
          "iopub.status.idle": "2024-03-17T20:19:21.434353Z",
          "shell.execute_reply.started": "2024-03-17T20:19:21.298381Z",
          "shell.execute_reply": "2024-03-17T20:19:21.433014Z"
        },
        "trusted": true,
        "id": "4GzEo006_iky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Initialize the Multi-layer Perceptron classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', max_iter=1000)\n",
        "\n",
        "# Fit the model on the training data\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "print(f'Neural Network Model Accuracy: {accuracy_mlp:.2f}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:12:18.115977Z",
          "iopub.execute_input": "2024-03-17T20:12:18.117224Z",
          "iopub.status.idle": "2024-03-17T20:12:18.527265Z",
          "shell.execute_reply.started": "2024-03-17T20:12:18.117176Z",
          "shell.execute_reply": "2024-03-17T20:12:18.526041Z"
        },
        "trusted": true,
        "id": "CZj8iVU-_ikz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = df_droped_age.drop('Outcome_0', axis=1)  # Features\n",
        "y = df_droped_age['Outcome_0']  # Target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:12:15.866311Z",
          "iopub.execute_input": "2024-03-17T20:12:15.867239Z",
          "iopub.status.idle": "2024-03-17T20:12:15.877531Z",
          "shell.execute_reply.started": "2024-03-17T20:12:15.867189Z",
          "shell.execute_reply": "2024-03-17T20:12:15.876531Z"
        },
        "trusted": true,
        "id": "f_30yrib_ikz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "scores = cross_val_score(logreg, X, y, cv=10)\n",
        "\n",
        "# Calculate the mean and standard deviation of the cross-validation scores\n",
        "mean_score = scores.mean()\n",
        "std_dev = scores.std()\n",
        "\n",
        "print(f\"Mean Accuracy: {mean_score:.2f}\")\n",
        "print(f\"Standard Deviation: {std_dev:.2f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:19:12.846076Z",
          "iopub.execute_input": "2024-03-17T20:19:12.847284Z",
          "iopub.status.idle": "2024-03-17T20:19:13.139102Z",
          "shell.execute_reply.started": "2024-03-17T20:19:12.847247Z",
          "shell.execute_reply": "2024-03-17T20:19:13.137981Z"
        },
        "trusted": true,
        "id": "JKw3LGhm_ikz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'df_droped_age' is your DataFrame after dropping 'Age_Group'\n",
        "X = df_droped_age.drop('Outcome_0', axis=1)  # Features\n",
        "y = df_droped_age['Outcome_0']  # Target\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "cv_scores = cross_val_score(rf, X, y, cv=10)\n",
        "\n",
        "# Calculate the mean and standard deviation of the cross-validation scores\n",
        "mean_cv_score = cv_scores.mean()\n",
        "std_dev_cv_score = cv_scores.std()\n",
        "\n",
        "print(f\"Mean CV Accuracy: {mean_cv_score:.2f}\")\n",
        "print(f\"CV Standard Deviation: {std_dev_cv_score:.2f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:19:02.467631Z",
          "iopub.execute_input": "2024-03-17T20:19:02.468186Z",
          "iopub.status.idle": "2024-03-17T20:19:05.708922Z",
          "shell.execute_reply.started": "2024-03-17T20:19:02.468143Z",
          "shell.execute_reply": "2024-03-17T20:19:05.707686Z"
        },
        "trusted": true,
        "id": "_gFMsLKb_ikz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Assuming 'df_droped_age' is your DataFrame after dropping 'Age_Group' and 'Outcome_1'\n",
        "X = df_droped_age.drop('Outcome_0', axis=1)  # Features\n",
        "y = df_droped_age['Outcome_0']  # Target\n",
        "\n",
        "# Initialize the Gradient Boosting Classifier\n",
        "gb = GradientBoostingClassifier()\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "cv_scores = cross_val_score(gb, X, y, cv=10)\n",
        "\n",
        "# Calculate the mean and standard deviation of the cross-validation scores\n",
        "mean_cv_score = cv_scores.mean()\n",
        "std_dev_cv_score = cv_scores.std()\n",
        "\n",
        "print(f\"Mean CV Accuracy: {mean_cv_score:.2f}\")\n",
        "print(f\"CV Standard Deviation: {std_dev_cv_score:.2f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:20:21.237967Z",
          "iopub.execute_input": "2024-03-17T20:20:21.23849Z",
          "iopub.status.idle": "2024-03-17T20:20:23.755839Z",
          "shell.execute_reply.started": "2024-03-17T20:20:21.23845Z",
          "shell.execute_reply": "2024-03-17T20:20:23.754478Z"
        },
        "trusted": true,
        "id": "71eW-oD1_ik0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Assuming 'df_droped_age' is your DataFrame after dropping unnecessary columns\n",
        "X = df_droped_age.drop('Outcome_0', axis=1)  # Features\n",
        "y = df_droped_age['Outcome_0']  # Target\n",
        "\n",
        "# Initialize and fit the Gradient Boosting Classifier\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "importances = gb.feature_importances_\n",
        "\n",
        "# Summarize feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print(f\"Feature {X.columns[i]}: {importance:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:23:06.792795Z",
          "iopub.execute_input": "2024-03-17T20:23:06.793437Z",
          "iopub.status.idle": "2024-03-17T20:23:07.081581Z",
          "shell.execute_reply.started": "2024-03-17T20:23:06.79339Z",
          "shell.execute_reply": "2024-03-17T20:23:07.080427Z"
        },
        "trusted": true,
        "id": "2JPjS7S7_ik0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Assuming 'df_droped_age' is your DataFrame after dropping unnecessary columns\n",
        "X = df_droped_age[['Glucose', 'BMI', 'Age']]  # Selecting the top features\n",
        "y = df_droped_age['Outcome_0']  # Target\n",
        "\n",
        "# Initialize and fit the Logistic Regression model\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X, y)\n",
        "\n",
        "# Get the coefficients of the features\n",
        "coefficients = logreg.coef_[0]\n",
        "for i, coef in enumerate(coefficients):\n",
        "    print(f\"Coefficient for {X.columns[i]}: {coef:.2f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:35:14.930908Z",
          "iopub.execute_input": "2024-03-17T20:35:14.931509Z",
          "iopub.status.idle": "2024-03-17T20:35:14.955816Z",
          "shell.execute_reply.started": "2024-03-17T20:35:14.93147Z",
          "shell.execute_reply": "2024-03-17T20:35:14.954375Z"
        },
        "trusted": true,
        "id": "G1o8SDSU_ik0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    # Add other parameters here\n",
        "}\n",
        "\n",
        "# Initialize the GB classifier\n",
        "gb = GradientBoostingClassifier()\n",
        "\n",
        "# Initialize the Grid Search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=gb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best Score: {best_score:.2f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-17T20:35:22.584299Z",
          "iopub.execute_input": "2024-03-17T20:35:22.584851Z",
          "iopub.status.idle": "2024-03-17T20:36:15.020458Z",
          "shell.execute_reply.started": "2024-03-17T20:35:22.58481Z",
          "shell.execute_reply": "2024-03-17T20:36:15.019033Z"
        },
        "trusted": true,
        "id": "eOQgixP7_ik0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    # Add other parameters here\n",
        "}\n",
        "\n",
        "# Initialize the GB classifier\n",
        "gb = GradientBoostingClassifier()\n",
        "\n",
        "# Initialize the Grid Search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=gb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best Score: {best_score:.2f}\")\n"
      ],
      "metadata": {
        "id": "xnZEL3sX_ik1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}